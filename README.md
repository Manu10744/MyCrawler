## MyCrawler

This is a crawler that i made for educational purposes. It is given a starting page, which is then analyzed for links.
Each found link is put in a list, which determines the links that should be crawled.
The crawler takes an argument 'depth' which determines how many links will actually be visited and crawled.

Making his way through the net, the crawler eventually collects all found URLs inside a list.
